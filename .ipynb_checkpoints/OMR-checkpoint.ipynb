{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#image processing\n",
    "from PIL import ImageFilter, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"test.jpg\")\n",
    "img.filter(ImageFilter.SHARPEN).save('test_1.jpg', 'JPEG', quality=100) \n",
    "del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load color image\n",
    "original_image = cv2.imread('test_1.jpg')\n",
    "image_color = original_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load image\n",
    "img = cv2.imread('test_1.jpg',0)\n",
    "# Thresholding the image\n",
    "(thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "# Invert the image\n",
    "img_bin = 255-img_bin \n",
    "cv2.imwrite(\"binary.jpg\",img_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all pixeles coordinates in a contour\n",
    "def get_cord(x,y,w,h):\n",
    "    idx=0\n",
    "    coords = []\n",
    "    for i in range (x,x+w):\n",
    "        for j in range (y,y+h):\n",
    "            coords.insert(idx,[i,j])\n",
    "            #print(idx, coords)\n",
    "            idx+=1\n",
    "            \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=2.8):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define two kernels\n",
    "-  Kernel to detect horizontal lines. \n",
    "-  Kernel to detect vertical lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a kernel length\n",
    "kernel_length = np.array(img).shape[1]//165\n",
    "\n",
    "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "\n",
    "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boxes(img_bin):\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//200\n",
    "\n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    \n",
    "    #### Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    \n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    \n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    #img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=1)\n",
    "    img_final_bin = ~img_final_bin\n",
    "    return cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(thres, img_final_bin) = find_boxes(img_bin)\n",
    "cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"top-to-bottom\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    " \n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    " \n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    " \n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    " \n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours for image, which will detect all the boxes\n",
    "contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Sort all the contours by top to bottom.\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cropped_path = 'Cropped/'\n",
    "for c in contours:\n",
    "    # Returns the location and width,height for every contour\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    #get all the pixels coordinates under contour\n",
    "    coordinates=[]\n",
    "    crd = get_cord(x,y,w,h)\n",
    "    coordinates.append(crd)\n",
    "# If the box height is greater then 20, widht is >80, then only save it as a box in \"cropped/\" folder.\n",
    "    if (w > 50 and h > 20) and w > 3*h and w<500 and h<250:\n",
    "        idx += 1\n",
    "        new_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(cropped_path+str(idx) + '.png', new_img)\n",
    "        #original_image[y:y+h, x:x+w] = adjust_gamma(original_image[y:y+h, x:x+w]) #Highlight Contours\n",
    "                \n",
    "        #draw contours\n",
    "        img_outlined=cv2.rectangle(image_color,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "cv2.imshow('rec',img_outlined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('rec',original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random testing and Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_1.jpg',0)\n",
    "edges = cv2.Canny(img,100,200,L2gradient=True)\n",
    "#cv2.imshow('Edges',edges)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imwrite('Opening.png', opening)\n",
    "#cv2.imshow('applied opening', opening)\n",
    "#dilation = cv2.dilate(edges,kernel,iterations = 1)\n",
    "#cv2.imshow('dilated_image',dilation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following function matches the right click coordinates with the pixel-values of each contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mouse_func(event, x, y, flags, param):\n",
    "    # 2 is the value for the right mouse click\n",
    "    if event == 2:\n",
    "        cord = [x,y] #right click co-ordinates\n",
    "        for c in contours:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if (w > 80 and h > 20) and w > 3*h and w<500 and h<250:\n",
    "                cor  = get_cord(x,y,w,h)\n",
    "                for i in cor:\n",
    "                    if i == cord:\n",
    "                        print (\"match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match\n",
      "match\n",
      "match\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow('camera',1)\n",
    "cv2.setMouseCallback(\"camera\",mouse_func)\n",
    "cv2.imshow('camera', img_outlined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
