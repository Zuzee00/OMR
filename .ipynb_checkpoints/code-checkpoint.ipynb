{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import ImageFilter, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp(image):\n",
    "    #Sharpening Image\n",
    "    image_2 = cv2.GaussianBlur(image,(0,0),3)\n",
    "    image_3 = cv2.addWeighted(image, 2, image_2, -1, 0)# Thresholding the image\n",
    "    #save sharped image\n",
    "    cv2.imwrite(\"sharp.jpg\",image_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load color image\n",
    "base_address = r'Inputs/'\n",
    "image_file = '3rd.png' \n",
    "original_image = cv2.imread(base_address+image_file)\n",
    "sharp(original_image)\n",
    "image_color = original_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load image\n",
    "img = cv2.imread('sharp.jpg',0)\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "# Thresholding the image\n",
    "(thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "#morpholigical operation\n",
    "img_bin_eroded=cv2.erode(img_bin, kernel, iterations=1)\n",
    "\n",
    "#Invert Image\n",
    "img_bin = ~img_bin_eroded\n",
    "\n",
    "#save image\n",
    "cv2.imwrite(\"binary.jpg\",img_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function opens a new window to show the input image\n",
    "def show_image(image):\n",
    "    cv2.imshow('image',image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all pixeles coordinates in a contour\n",
    "def get_cord(x,y,w,h):\n",
    "    idx=0\n",
    "    coords = []\n",
    "    for i in range (x,x+w):\n",
    "        for j in range (y,y+h):\n",
    "            coords.insert(idx,[i,j])\n",
    "            #print(idx, coords)\n",
    "            idx+=1\n",
    "            \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel\n",
    "**Define two kernels**\n",
    "-  Kernel to detect horizontal lines. \n",
    "-  Kernel to detect vertical lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a kernel length\n",
    "kernel_length = np.array(img).shape[1]//165\n",
    "\n",
    "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "\n",
    "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boxes(img_bin):\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//195\n",
    "\n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    \n",
    "    #### Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    \n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "    \n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    \n",
    "    #img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=1)\n",
    "    img_final_bin = ~img_final_bin\n",
    "    return cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(thres, img_final_bin) = find_boxes(img_bin)\n",
    "cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"top-to-bottom\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    " \n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    " \n",
    "    # handle if we are sorting against the y-coordinate rather than the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "        \n",
    "    # construct the list of bounding boxes and sort them from top to bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    " \n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours for image, which will detect all the boxes\n",
    "contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort all the contours by top to bottom.\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cropped_path = 'Cropped/'\n",
    "for c in contours:\n",
    "    \n",
    "    # Returns the location and width,height for every contour\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    \n",
    "    #get all the pixels coordinates under contour\n",
    "    coordinates=[]\n",
    "    crd = get_cord(x,y,w,h)\n",
    "    coordinates.append(crd)\n",
    "    #\n",
    "    if (w < 30 and h>15 and w>15 and h < 30):\n",
    "        idx+=1\n",
    "        #extract ROI\n",
    "        new_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(cropped_path+str(idx)+ '.png', new_img)\n",
    "        \n",
    "        #draw boundary of contour\n",
    "        img_outlined=cv2.rectangle(image_color,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    \n",
    "    # If the box height is greater then 20, widht is >80, then only save it as a box in \"cropped/\" folder.\n",
    "    if (w > 20 and h > 10) and w > 1.5*h and w<445 and h<40:\n",
    "        idx += 1\n",
    "        \n",
    "        #ROI extraction\n",
    "        new_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(cropped_path+str(idx) + '.png', new_img)\n",
    "        \n",
    "        #draw contours\n",
    "        img_outlined=cv2.rectangle(image_color,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "show_image(img_outlined)\n",
    "del img_outlined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Following cell:**\n",
    "1. gets pixeles of contours\n",
    "2. gets coordinate of right-click \n",
    "3. compare coordinates (click) with pixel coordinate from contour\n",
    "4. if they match, draw boundary of that contour\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle.\n",
    "def mouse_func(event, x, y, flags, param):\n",
    "    global drawing,mode\n",
    "    \n",
    "    # 2 is the value for the right mouse click\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        drawing = True\n",
    "        \n",
    "        #right click co-ordinates\n",
    "        cord = [x,y] \n",
    "        for c in contours:\n",
    "            \n",
    "            #staring points (x,y) and dimensions of contour (w=width, h= height)\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if (w < 30 and h>15 and w>15 and h < 30):\n",
    "                cor = get_cord(x,y,w,h)\n",
    "                for i in cor:\n",
    "                    if i == cord:\n",
    "                        if drawing == True:\n",
    "                            if mode == True:\n",
    "                                cv2.rectangle(original_image,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "            if (w > 20 and h > 10) and w > 1.5*h and w<445 and h<40:\n",
    "                cor  = get_cord(x,y,w,h)\n",
    "                for i in cor:\n",
    "                    if i == cord:\n",
    "                        if drawing == True:\n",
    "                            if mode == True:\n",
    "                                cv2.rectangle(original_image,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "                        #print (\"It's a box\\n\")\n",
    "                        #print ('Dimension: '+ str((x+w)-x)+ \" X \"+ str((y+h)-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('Picture',1)\n",
    "cv2.setMouseCallback(\"Picture\",mouse_func)\n",
    "while(1):\n",
    "    cv2.imshow('Picture', original_image)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "        \n",
    "    # if pressed \"p\" exit the pop-up window\n",
    "    elif k == ord('p'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**EXTRA**\n",
    "\n",
    "Below is the experimentation area\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse(event, x, y, flags, param):\n",
    "    if event ==2 :\n",
    "        for c in contours:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if (8 < w < 20 and h > 8):\n",
    "        imgt=cv2.rectangle(original_image,(x,y),(x-w,y-h),(0,0,255),2)\n",
    "                \n",
    "        cv2.imshow('figure',imgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('camera',1)\n",
    "cv2.setMouseCallback(\"camera\",mouse)\n",
    "cv2.imshow('camera', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show all contours\n",
    "for c in contours:\n",
    "    \n",
    "    # Returns the location and width,height for every contour\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    clk=cv2.rectangle(image_color,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "show_image(clk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
