{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#image processing\n",
    "from PIL import ImageFilter, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"2nd.png\")\n",
    "img.filter(ImageFilter.SHARPEN).save('test_1.jpg', 'JPEG', quality=1000) \n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load color image\n",
    "original_image = cv2.imread('test_1.jpg')\n",
    "image_color = original_image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load image\n",
    "img = cv2.imread('test_1.jpg',0)\n",
    "# Thresholding the image\n",
    "(thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "# Invert the image\n",
    "img_bin = 255-img_bin \n",
    "cv2.imwrite(\"binary.jpg\",img_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    cv2.imshow('image',image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all pixeles coordinates in a contour\n",
    "def get_cord(x,y,w,h):\n",
    "    idx=0\n",
    "    coords = []\n",
    "    for i in range (x,x+w):\n",
    "        for j in range (y,y+h):\n",
    "            coords.insert(idx,[i,j])\n",
    "            #print(idx, coords)\n",
    "            idx+=1\n",
    "            \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Define two kernels**\n",
    "-  Kernel to detect horizontal lines. \n",
    "-  Kernel to detect vertical lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a kernel length\n",
    "kernel_length = np.array(img).shape[1]//165\n",
    "\n",
    "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "\n",
    "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boxes(img_bin):\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//195\n",
    "\n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    \n",
    "    #### Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    \n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    \n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=1)\n",
    "    #img_final_bin = ~img_final_bin\n",
    "    return cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(thres, img_final_bin) = find_boxes(img_bin)\n",
    "cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"top-to-bottom\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    " \n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    " \n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    " \n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    " \n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours for image, which will detect all the boxes\n",
    "contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Sort all the contours by top to bottom.\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "cropped_path = 'Cropped/'\n",
    "for c in contours:\n",
    "    # Returns the location and width,height for every contour\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    #get all the pixels coordinates under contour\n",
    "    coordinates=[]\n",
    "    crd = get_cord(x,y,w,h)\n",
    "    coordinates.append(crd)\n",
    "    if (w < 30 and h>5 and w>10 and h < 30):\n",
    "        idx+=1\n",
    "        new_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(cropped_path+str(idx)+ '.png', new_img)\n",
    "        img_outlined=cv2.rectangle(image_color,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "# If the box height is greater then 20, widht is >80, then only save it as a box in \"cropped/\" folder.\n",
    "    if (w > 12 and h > 15) and w > 3*h and w<420 and h<40:\n",
    "        idx += 1\n",
    "        new_img = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(cropped_path+str(idx) + '.png', new_img)\n",
    "        #original_image[y:y+h, x:x+w] = adjust_gamma(original_image[y:y+h, x:x+w]) #Highlight Contours\n",
    "\n",
    "        #draw contours\n",
    "        img_outlined=cv2.rectangle(image_color,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "show_image(img_outlined)\n",
    "del img_outlined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following function matches the right click coordinates with the pixel-values of each contour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle.\n",
    "def mouse_func(event, x, y, flags, param):\n",
    "    global drawing,mode\n",
    "    # 2 is the value for the right mouse click\n",
    "    if event == 2:\n",
    "        drawing = True\n",
    "        cord = [x,y] #right click co-ordinates\n",
    "        for c in contours:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if (w < 20 and h > 5) and (w>5 and h < 25):\n",
    "                cor = get_cord(x,y,w,h)\n",
    "                for i in cor:\n",
    "                    if i == cord:\n",
    "                        if drawing == True:\n",
    "                            if mode == True:\n",
    "                                cv2.rectangle(original_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "            if (w > 20 and h > 15) and w > 3*h and w<445 and h<40:\n",
    "                cor  = get_cord(x,y,w,h)\n",
    "                for i in cor:\n",
    "                    if i == cord:\n",
    "                        if drawing == True:\n",
    "                            if mode == True:\n",
    "                                cv2.rectangle(original_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                        #print (\"It's a box\\n\")\n",
    "                        #print ('Dimension: '+ str((x+w)-x)+ \" X \"+ str((y+h)-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('camera',1)\n",
    "cv2.setMouseCallback(\"camera\",mouse_func)\n",
    "while(1):\n",
    "    cv2.imshow('camera', original_image)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == ord('p'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random testing and Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_1.jpg',0)\n",
    "edges = cv2.Canny(img,100,200,L2gradient=True)\n",
    "#cv2.imshow('Edges',edges)\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imwrite('Opening.png', opening)\n",
    "cv2.imshow('applied opening', opening)\n",
    "#dilation = cv2.dilate(edges,kernel,iterations = 1)\n",
    "#cv2.imshow('dilated_image',dilation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA\n",
    ">Below is the experimentation area\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = cv2.imread('test.jpg')\n",
    "#Sharpening Image\n",
    "image_2 = cv2.GaussianBlur(image_1,(0,0),3)\n",
    "image_3 = cv2.addWeighted(image_1, 2.0, image_2, -0.9, 0)# Thresholding the image\n",
    "#save sharped image\n",
    "show_image(image_3)\n",
    "cv2.imwrite(\"test_9.jpg\",image_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse(event, x, y, flags, param):\n",
    "    #if event ==2 :\n",
    "        for c in contours:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            #if (8< w < 20 and h >8):#and w==h:\n",
    "        imgt=cv2.rectangle(original_image,(x,y),(x-w,y-h),(0,0,255),2)\n",
    "                \n",
    "        cv2.imshow('figure',imgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('camera',1)\n",
    "cv2.setMouseCallback(\"camera\",mouse)\n",
    "cv2.imshow('camera', original_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
